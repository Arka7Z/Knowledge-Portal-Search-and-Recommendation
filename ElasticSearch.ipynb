{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "import requests\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\\n  \"name\" : \"cpusrv-xeon-101\",\\n  \"cluster_name\" : \"elasticsearch\",\\n  \"cluster_uuid\" : \"uHSOXgwSQoe6tNgXTGU5kA\",\\n  \"version\" : {\\n    \"number\" : \"7.6.1\",\\n    \"build_flavor\" : \"default\",\\n    \"build_type\" : \"tar\",\\n    \"build_hash\" : \"aa751e09be0a5072e8570670309b1f12348f023b\",\\n    \"build_date\" : \"2020-02-29T00:15:25.529771Z\",\\n    \"build_snapshot\" : false,\\n    \"lucene_version\" : \"8.4.0\",\\n    \"minimum_wire_compatibility_version\" : \"6.8.0\",\\n    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\\n  },\\n  \"tagline\" : \"You Know, for Search\"\\n}\\n'\n"
     ]
    }
   ],
   "source": [
    "res = requests.get('http://localhost:9200')\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDs under Consideration for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475839"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IDoutfileName = \"./data/dblpPaperIDs_\" + str(2) + \"Thresholded.json\"\n",
    "with open(IDoutfileName, 'r') as f:\n",
    "    paperIdList = json.load(f)\n",
    "len(paperIdList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "AITopLevelTopics = set(['Artificial intelligence', 'Computer vision', 'Data mining',\n",
    "                     'Data science', 'Machine learning', 'Natural language processing',\n",
    "                     'Pattern recognition', 'Speech recognition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "papersUnderConsideration = set(paperIdList)\n",
    "PapersOutFileName = './data/es/dblp_AIpapers_v1.json'\n",
    "with open('dblp_papers_v11.txt', 'r') as file:\n",
    "    with open(PapersOutFileName, 'w') as outfile:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "            paperID = data.get('id','')\n",
    "            if paperID not in papersUnderConsideration:\n",
    "                continue\n",
    "\n",
    "            dataDict = dict()\n",
    "            \n",
    "            dataDict['id'] = paperID\n",
    "            dataDict['title'] = data.get('title', '')\n",
    "#             references = list()\n",
    "#             for reference in data.get('references',[]):\n",
    "#                 if reference in papersUnderConsideration:\n",
    "#                     references.append(reference)\n",
    "#             dataDict['references'] = references\n",
    "            if 'venue' in data:\n",
    "                dataDict['venue'] = data['venue']['raw']\n",
    "            \n",
    "            dataDict['authors'] = []\n",
    "            if 'authors' in data:\n",
    "                dataDict['authors'] = [d['name'] for d in data['authors']]\n",
    "                \n",
    "            dataDict['year'] = data['year']\n",
    "    \n",
    "            dataDict['abstract'] = []\n",
    "            if 'indexed_abstract' in data:\n",
    "                dataDict['abstract'] = [w for w in data['indexed_abstract']['InvertedIndex'].keys() if len(w) > 1]\n",
    "            abstractString = ' '.join(word for word in dataDict['abstract'])\n",
    "            abstractString = abstractString.replace('\\n', ' ').replace('\\r', '')\n",
    "            dataDict['abstract'] = abstractString\n",
    "            \n",
    "            dataDict['fos'] = [ d['name'] for d in data['fos'] if d['w'] > 0 or d['name'] in AITopLevelTopics]\n",
    "            \n",
    "            indexDict = {'index': {'_id': dataDict['id']}}\n",
    "            \n",
    "            json.dump(indexDict, outfile)\n",
    "            outfile.write('\\n')\n",
    "            json.dump(dataDict, outfile)\n",
    "            outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = []\n",
    "with open(PapersOutFileName, 'r') as file:\n",
    "    for line in file:\n",
    "        data = json.loads(line)\n",
    "        body.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475839"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = [body[i] for i in range(len(body)) if i % 2 != 0]\n",
    "len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99baa224ae84af48a7535e4d1448152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=475839), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for record in tqdm(records):\n",
    "    res = es.index(index='dblp_v1',doc_type='paper',id=record['id'],body=record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['id', 'title', 'venue', 'authors', 'year', 'abstract', 'fos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "queryBody = {\n",
    "    \"query\": {\n",
    "        \"multi_match\" : {\n",
    "            \"query\" : \"sentence embeddings\",\n",
    "            \"fields\" : ['title', 'abstract']\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "res= es.search(index='dblp_v1',body=queryBody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 17,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': {'value': 6584, 'relation': 'eq'},\n",
       "  'max_score': 16.353527,\n",
       "  'hits': [{'_index': 'dblp_v1',\n",
       "    '_type': 'paper',\n",
       "    '_id': '2175723921',\n",
       "    '_score': 16.353527,\n",
       "    '_source': {'id': '2175723921',\n",
       "     'title': 'Towards Universal Paraphrastic Sentence Embeddings',\n",
       "     'venue': 'international conference on learning representations',\n",
       "     'authors': ['John Wieting',\n",
       "      'Mohit Bansal',\n",
       "      'Kevin Gimpel',\n",
       "      'Karen Livescu'],\n",
       "     'year': 2016,\n",
       "     'abstract': 'Abstract: We consider the problem of learning general-purpose, paraphrastic sentence embeddings based on supervision from Paraphrase Database (Ganitkevitch et al., 2013). compare six compositional architectures, evaluating them annotated textual similarity datasets drawn both same distribution as training data and wide range other domains. find that most complex such long short-term memory (LSTM) recurrent neural networks, perform best in-domain data. However, in out-of-domain scenarios, simple architectures word averaging vastly outperform LSTMs. Our simplest model is even competitive with systems tuned for particular tasks while also being extremely efficient easy to use.  In order better understand how these compare, we conduct further experiments three supervised NLP tasks: similarity, entailment, sentiment classification. again models well outperforming classification, LSTM performs very strongly-even recording new state-of-the-art performance Stanford Sentiment Treebank.  We then demonstrate combine our pretrained tasks, using prior black box feature extractor. This leads rivaling state art SICK entailment tasks. release all resources research community hope they can serve baseline work universal embeddings.',\n",
       "     'fos': ['Machine learning',\n",
       "      'Pattern recognition',\n",
       "      'Artificial intelligence',\n",
       "      'Natural language processing',\n",
       "      'Logical consequence',\n",
       "      'Computer science',\n",
       "      'Treebank',\n",
       "      'Sentence',\n",
       "      'Recurrent neural network',\n",
       "      'Paraphrase']}}]}}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -XPOST localhost:9200/dblp_v1/paper/_bulk --data-binary  @/home/du0/15CS30003/nairp2/ontology/data/es/dblp_AIpapers_v1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "health status index   uuid                   pri rep docs.count docs.deleted store.size pri.store.size\r\n",
      "yellow open   test    bT3mFwXHSvimc6ztC8q7Lw   1   1          4            0     15.7kb         15.7kb\r\n",
      "yellow open   dblp_v1 xbTu48DzRoijqo1DTXQQlw   1   1     475839            0    629.4mb        629.4mb\r\n"
     ]
    }
   ],
   "source": [
    "!curl 'localhost:9200/_cat/indices?v'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clio_lite import clio_search\n",
    "from clio_lite import clio_keywords\n",
    "\n",
    "url = \"http://localhost:9200\"\n",
    "index = \"dblp_v1\"\n",
    "query = \"finance\"\n",
    "\n",
    "keywords = clio_keywords(url=url, index=index, query=query, \n",
    "                         fields=['title','abstract'],\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'key': 'finance', 'score': 1715.9172190632926},\n",
       " {'key': 'economics', 'score': 13.099794878825975},\n",
       " {'key': 'financial', 'score': 12.132793995808761},\n",
       " {'key': 'applications', 'score': 8.201792215672679},\n",
       " {'key': 'portfolio', 'score': 6.861277926869297},\n",
       " {'key': 'stock', 'score': 6.691882871534194},\n",
       " {'key': 'bankruptcy', 'score': 5.276549542559988},\n",
       " {'key': 'cvar', 'score': 4.96973724661665},\n",
       " {'key': 'intraday', 'score': 3.2293785689523222},\n",
       " {'key': 'series', 'score': 1.85564460243314},\n",
       " {'key': 'systems', 'score': 1.5042725679228746}]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type('hello'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
