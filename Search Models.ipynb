{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "import requests\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import re\n",
    "import fasttext \n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import hnswlib\n",
    "from collections import defaultdict, Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "tf.enable_eager_execution()\n",
    "module_url = \"./module/UnivTrans\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"]\n",
    "model = hub.load(module_url)\n",
    "def embed(inputText):\n",
    "    return model(inputText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQueryEmbedding(query, embeddingType='fastText'):\n",
    "    \n",
    "    '''Get embedding for a single query. Query is pre-processed in this function itself'''\n",
    "\n",
    "    translator = str.maketrans('', '', string.punctuation) \n",
    "    query.strip()\n",
    "    query = query.translate(translator)\n",
    "    query = ' '.join(query.split())\n",
    "    \n",
    "    if embeddingType == 'fastText':\n",
    "        embedding = fasttextModel.get_word_vector(query)\n",
    "    elif embeddingType == 'USE':\n",
    "        embedding = embed([queryList])[0].numpy()\n",
    "        \n",
    "    return np.asarray(embedding)\n",
    "\n",
    "\n",
    "def getQueryEmbeddings(queryList, embeddingType='fastText'):\n",
    "    '''Get embedding list for a list of queries. Query is pre-processed in this function itself''' \n",
    "    embeddings = []\n",
    "    \n",
    "    ## Preprocessing\n",
    "    translator = str.maketrans('', '', string.punctuation) \n",
    "    for i in range(len(queryList)):\n",
    "            queryList[i].strip()\n",
    "            queryList[i] = queryList[i].translate(translator)\n",
    "            queryList[i] = ' '.join(queryList[i].split())\n",
    "    \n",
    "    if embeddingType == 'fastText':\n",
    "        for query in queryList:\n",
    "            embedding = fasttextModel.get_word_vector(query)\n",
    "            embeddings.append(embedding)\n",
    "    elif embeddingType == 'USE':\n",
    "        embeddings = embed([queryList]).numpy()\n",
    "        \n",
    "    return np.asarray(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocumentEmbeddings(docIDList, method='abstract', embeddingType='fastText'):\n",
    "    docIDSet = set(docIDList)\n",
    "    embeddingDictForDocs = dict()\n",
    "    \n",
    "    if method=='abstract':\n",
    "        if embeddingType == 'fastText':\n",
    "            filename = './data/dblpAbstract_2Thresholded_FT_Embeddings.json'\n",
    "        elif embeddingType == 'USE':\n",
    "            filename = './data/dblp_Abstract_2Thresholded_USE_Trans_Embeddings.json'\n",
    "        with open(filename, 'r') as file:\n",
    "                for line in file:\n",
    "                    data = json.loads(line)\n",
    "                    if data['id'] in docIDSet:\n",
    "                        embeddingDictForDocs[data['id']] = data['embedding']\n",
    "                        \n",
    "    elif method=='title':\n",
    "        if embeddingType == 'fastText':\n",
    "            filename = './data/dblpTitle_2Thresholded_FT_Embeddings.json'\n",
    "        elif embeddingType == 'USE':\n",
    "            filename = './data/dblp_Title_2Thresholded_USE_Trans_Embeddings.json'\n",
    "        with open(filename, 'r') as file:\n",
    "                for line in file:\n",
    "                    data = json.loads(line)\n",
    "                    if data['id'] in docIDSet:\n",
    "                        embeddingDictForDocs[data['id']] = data['embedding']\n",
    "    \n",
    "    elif method=='fos':\n",
    "        records = []\n",
    "        PapersOutFileName = './data/es/dblp_AIpapers_v1.json'\n",
    "        i = 0\n",
    "\n",
    "        with open(PapersOutFileName, 'r') as file:\n",
    "            for line in file:\n",
    "                if i % 2 != 0:\n",
    "                    data = json.loads(line)\n",
    "                    if data['id'] in docIDSet:\n",
    "                        records.append(data)\n",
    "                i += 1\n",
    "        \n",
    "        assert len(records) == len(docIDList)\n",
    "        \n",
    "        if embeddingType == 'fastText':\n",
    "            fileName = './data/dblp_fos_FT_Phrase_embeddings.json'\n",
    "        elif embeddingType == 'USE':\n",
    "            filename = './data/dblp_fos_USE_embeddings.json'\n",
    "        \n",
    "        embeddingDict = dict()\n",
    "        with open(filename, 'r') as file:\n",
    "            for line in file:\n",
    "                data = json.loads(line)\n",
    "                embeddingDict[data['fos']] = np.asarray(data['embedding']) \n",
    "        \n",
    "        for record in tqdm(records):\n",
    "            recordEmbeddingList = []\n",
    "            for fos in record['fos']:\n",
    "                recordEmbeddingList.append(embeddingDict[fos])\n",
    "            embeddingDictForDocs[record['id']] = np.mean(recordEmbeddingList, axis = 0)\n",
    "            \n",
    "    elif method=='fosIdf':\n",
    "        records = []\n",
    "        PapersOutFileName = './data/es/dblp_AIpapers_v1.json'\n",
    "        i = 0\n",
    "\n",
    "        with open(PapersOutFileName, 'r') as file:\n",
    "            for line in file:\n",
    "                if i % 2 != 0:\n",
    "                    data = json.loads(line)\n",
    "                    records.append(data)\n",
    "                i += 1\n",
    "        \n",
    "        if embeddingType == 'fastText':\n",
    "            fileName = './data/dblp_fos_FT_Phrase_embeddings.json'\n",
    "        elif embeddingType == 'USE':\n",
    "            filename = './data/dblp_fos_USE_embeddings.json'\n",
    "        \n",
    "        embeddingDict = dict()\n",
    "        fosCount = dict()\n",
    "        N = len(records)\n",
    "        with open(filename, 'r') as file:\n",
    "            for line in file:\n",
    "                data = json.loads(line)\n",
    "                embeddingDict[data['fos']] = np.asarray(data['embedding']) \n",
    "                fosCount[data['fos']] = data['count']\n",
    "        \n",
    "        for record in tqdm(records):\n",
    "            recordEmbeddingList = []\n",
    "            weightList = []\n",
    "            for fos in record['fos']:\n",
    "                recordEmbeddingList.append(embeddingDict[fos] * (N / fosCount[fos]))\n",
    "                weightList.append((N / fosCount[fos]))\n",
    "            embeddingDictForDocs[record['id']] = np.mean(recordEmbeddingList, axis = 0) / np.sum(weightList)\n",
    "            \n",
    "        embeddings = []\n",
    "        for docID in docIDList:\n",
    "            embeddings.append(embeddingDictForDocs[docID])\n",
    "        assert len(embeddings) == len(docIDList)\n",
    "        return np.asarray(embeddings)\n",
    "\n",
    "\n",
    "\n",
    "def getAllDocumentEmbeddings(method='abstract', embeddingType='fastText'):\n",
    "    \n",
    "    embeddings = []\n",
    "    \n",
    "    if method=='abstract':\n",
    "        if embeddingType == 'fastText':\n",
    "            filename = './data/dblpAbstract_2Thresholded_FT_Embeddings.json'\n",
    "        elif embeddingType == 'USE':\n",
    "            filename = './data/dblp_Abstract_2Thresholded_USE_Trans_Embeddings.json'\n",
    "        with open(filename, 'r') as file:\n",
    "                for line in file:\n",
    "                    data = json.loads(line)\n",
    "                    embedding = data['embedding']\n",
    "                    embeddings.append(embedding)\n",
    "    elif method=='title':\n",
    "        if embeddingType == 'fastText':\n",
    "            filename = './data/dblpTitle_2Thresholded_FT_Embeddings.json'\n",
    "        elif embeddingType == 'USE':\n",
    "            filename = './data/dblp_Title_2Thresholded_USE_Trans_Embeddings.json'\n",
    "        with open(filename, 'r') as file:\n",
    "                for line in file:\n",
    "                    data = json.loads(line)\n",
    "                    embedding = data['embedding']\n",
    "                    embeddings.append(embedding)\n",
    "    \n",
    "    elif method=='fos':\n",
    "        records = []\n",
    "        PapersOutFileName = './data/es/dblp_AIpapers_v1.json'\n",
    "        i = 0\n",
    "\n",
    "        with open(PapersOutFileName, 'r') as file:\n",
    "            for line in file:\n",
    "                if i % 2 != 0:\n",
    "                    data = json.loads(line)\n",
    "                    records.append(data)\n",
    "                i += 1\n",
    "        \n",
    "        if embeddingType == 'fastText':\n",
    "            fileName = './data/dblp_fos_FT_Phrase_embeddings.json'\n",
    "        elif embeddingType == 'USE':\n",
    "            filename = './data/dblp_fos_USE_embeddings.json'\n",
    "        \n",
    "        embeddingDict = dict()\n",
    "        with open(filename, 'r') as file:\n",
    "            for line in file:\n",
    "                data = json.loads(line)\n",
    "                embeddingDict[data['fos']] = np.asarray(data['embedding']) \n",
    "        \n",
    "        for record in tqdm(records):\n",
    "            recordEmbeddingList = []\n",
    "            for fos in record['fos']:\n",
    "                recordEmbeddingList.append(embeddingDict[fos])\n",
    "            embeddings.append(np.mean(recordEmbeddingList, axis = 0))\n",
    "            \n",
    "    elif method=='fosIdf':\n",
    "        records = []\n",
    "        PapersOutFileName = './data/es/dblp_AIpapers_v1.json'\n",
    "        i = 0\n",
    "\n",
    "        with open(PapersOutFileName, 'r') as file:\n",
    "            for line in file:\n",
    "                if i % 2 != 0:\n",
    "                    data = json.loads(line)\n",
    "                    records.append(data)\n",
    "                i += 1\n",
    "        \n",
    "        if embeddingType == 'fastText':\n",
    "            fileName = './data/dblp_fos_FT_Phrase_embeddings.json'\n",
    "        elif embeddingType == 'USE':\n",
    "            filename = './data/dblp_fos_USE_embeddings.json'\n",
    "        \n",
    "        embeddingDict = dict()\n",
    "        fosCount = dict()\n",
    "        N = len(records)\n",
    "        with open(filename, 'r') as file:\n",
    "            for line in file:\n",
    "                data = json.loads(line)\n",
    "                embeddingDict[data['fos']] = np.asarray(data['embedding']) \n",
    "                fosCount[data['fos']] = data['count']\n",
    "        \n",
    "        for record in tqdm(records):\n",
    "            recordEmbeddingList = []\n",
    "            weightList = []\n",
    "            for fos in record['fos']:\n",
    "                recordEmbeddingList.append(embeddingDict[fos] * (N / fosCount[fos]))\n",
    "                weightList.append((N / fosCount[fos]))\n",
    "            embeddings.append(np.mean(recordEmbeddingList, axis = 0) / np.sum(weightList))\n",
    "    \n",
    "    return np.asarray(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search using Direct embedding Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildIndexer(docEmbeddings):\n",
    "    numElements = len(docEmbeddings)\n",
    "    dimension = len(docEmbeddings[0])\n",
    "    embeddings = np.asarray(docEmbeddings)\n",
    "    data_labels = np.arange(numElements)\n",
    "    p = hnswlib.Index(space = 'cosine', dim = dimension) # possible options are l2, cosine or ip\n",
    "    p.init_index(max_elements = numElements, ef_construction = 200, M = 20)\n",
    "    p.add_items(embeddings, data_labels)\n",
    "    p.set_ef(50) \n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadIndexer(filepath, numElements):\n",
    "    p = hnswlib.Index(space='cosine', dim=dimension)  # the space can be changed - keeps the data, alters the distance function.\n",
    "    p.load_index(\"./models/fastTexthnswlib.bin\", max_elements =numElements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchWithEmbedding(queryList, K=10, method='abstract', embeddingType='fastText'):\n",
    "    IDList = []\n",
    "    with open('./data/dblp_AIpapers2Thresholded.json', 'r') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "            IDList.append(data['id'])\n",
    "\n",
    "    docEmbeddings = getAllDocumentEmbeddings(method=method, embeddingType=embeddingType)\n",
    "    queryEmbeddings = getQueryEmbeddings(queryList, )\n",
    "    p = buildIndexer(docEmbeddings)\n",
    "\n",
    "    labels, _ = p.knn_query(queryEmbeddings, k = K )\n",
    "    for i in range(len(labels)):\n",
    "        labels[i] = [IDList[ind] for ind in labels[i]]\n",
    "        \n",
    "    return labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def weight(score, esScore):\n",
    "    embeddingWeight = 0.8\n",
    "    s = embeddingWeight * score + (1 - embeddingWeight) * esScore\n",
    "    return s\n",
    "\n",
    "\n",
    "def normalize(lis):\n",
    "    _min = min(lis)\n",
    "    _max = max(lis)\n",
    "    lis  = [(x - _min)/(_max - _min) for x in lis]\n",
    "    return lis\n",
    "\n",
    "def rankList(query, docList, esScoreList=None, K=10):\n",
    "    '''\n",
    "    ReRank documents in the docList wrt the query\n",
    "\n",
    "    Parameters: \n",
    "    query (str): query wrt. which the documents will be ranked\n",
    "\n",
    "    doclist(list[str]): IDs of the documents to rerank, len(doclist >= K)\n",
    "\n",
    "    esScoreList(list[int]): scores of the documents as returned by Elastic Search\n",
    "\n",
    "    k(int): number of top documents to return after re-ranking\n",
    "\n",
    "    Returns: \n",
    "    list[str]: re-ranked list of document IDs\n",
    "    '''\n",
    "    queryEmbedding = getQueryEmbedding(query, method='fastText')\n",
    "    docEmbeddings = getDocumentEmbeddings(docList, method ='fos', embeddingType='fastText')\n",
    "    \n",
    "    cosineSimScores = [ cosine_similarity(queryEmbedding, docEmbedding) for docEmbedding in docEmbeddings]\n",
    "    if esScoreList is None:\n",
    "        IDsWithScore = [(score, ID) in score, ID in zip(cosineSimScores, docList)]\n",
    "    elif esScoreList is not None:\n",
    "         IDsWithScore = [(weight(score, esScore), ID) in score, ID, esScore in zip(cosineSimScores, docList, esScoreList)]\n",
    "    IDsWithScore.sort(reverse=True)\n",
    "    IDsWithScore = IDsWithScore[:K + 1]                    ## Keep top-K documents only\n",
    "    \n",
    "    return [ID for _,ID in IDsWithScore]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Search with Elastic Search\n",
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "\n",
    "def elasticSearch(queryList, index='dblp_v1', K = 10):\n",
    "    fields = ['id', 'title', 'venue', 'authors', 'year', 'abstract', 'fos']\n",
    "    queryBody = {\n",
    "    \"query\": {\n",
    "        \"multi_match\" : {\n",
    "            \"query\" : \"sentence embeddings\",\n",
    "            \"fields\" : ['title', 'abstract', 'authors']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "    queryBody['size'] = K\n",
    "    searchResults = []\n",
    "    for query in queryList:\n",
    "        queryBody['query']['multi_match']['query'] = query\n",
    "        res= es.search(index,body=queryBody)\n",
    "        searchResults.append([hit['_id'] for hit in res['hits']['hits']])\n",
    "    return searchResults\n",
    "\n",
    "def rankedElasticSearch(queryList, index='dblp_v1', K = 10, includeEsScores=False, rerank=True):\n",
    "    fields = ['id', 'title', 'venue', 'authors', 'year', 'abstract', 'fos']\n",
    "    queryBody = {\n",
    "    \"query\": {\n",
    "        \"multi_match\" : {\n",
    "            \"query\" : \"sentence embeddings\",\n",
    "            \"fields\" : ['title^3', 'abstract', 'authors', 'fos^2']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "    if rerank:\n",
    "        queryBody['size'] = 2 * K\n",
    "    else:\n",
    "        queryBody['size'] = K\n",
    "    queryBody['query']['multi_match']['fuzziness'] = 'AUTO'\n",
    "    searchResults = []\n",
    "    for query in queryList:\n",
    "        queryBody['query']['multi_match']['query'] = query\n",
    "        res= es.search(index,body=queryBody)\n",
    "        initList = [hit['_id'] for hit in res['hits']['hits']]\n",
    "        esScoreList = [hit['_score'] for hit in res['hits']['hits']]\n",
    "        esScoreList = normalize(esScoreList)\n",
    "        if rerank:\n",
    "            if includeEsScores:\n",
    "                searchResults.append(rankList(query, initList, esScoreList = esScoreList))\n",
    "            else:\n",
    "                searchResults.append(rankList(query, initList))\n",
    "        else:\n",
    "            searchResults.append(initList)\n",
    "    return searchResults\n",
    "\n",
    "def rankedMLTElasticSearch(queryList, index='dblp_v1', K = 10, includeEsScores=False):\n",
    "    fields = ['id', 'title', 'venue', 'authors', 'year', 'abstract', 'fos']\n",
    "    queryBody = {\n",
    "    \"query\": {\n",
    "        \"more_like_this\" : {\n",
    "            \"like\" : \"sentence embeddings\",\n",
    "            \"fields\" : ['title^3', 'abstract', 'authors', 'fos^2']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "   \n",
    "    \n",
    "    \n",
    "    queryBody['size'] = 5 * K\n",
    "    \n",
    "    searchResults = []\n",
    "    for query in queryList:\n",
    "        queryBody['query']['more_like_this']['like'] = query\n",
    "        res= es.search(index,body=queryBody)\n",
    "        initList = [hit['_id'] for hit in res['hits']['hits']]\n",
    "        esScoreList = [hit['_score'] for hit in res['hits']['hits']] \n",
    "        esScoreList = normalize(esScoreList)\n",
    "        if includeEsScores:\n",
    "            searchResults.append(rankList(query, initList, esScoreList = esScoreList))\n",
    "        else:\n",
    "            searchResults.append(rankList(query, initList))\n",
    "        \n",
    "        \n",
    "    return searchResults\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fos+title'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
